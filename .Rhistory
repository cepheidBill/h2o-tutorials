library(h2o)
h2o.init(nthreads = -1, #Number of threads -1 means use all cores on your machine
max_mem_size = "8G")  #max mem size is the maximum memory to allocate to H2O
loan_csv <- "https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv"
data <- h2o.importFile(loan_csv)  # 163,987 rows x 15 columns
dim(data)
head(data)
class(data)
df <- fread(data)
library(data.table)
library(tidyverse)
df <- fread(data)
df <- as.data.table(data)
unique(df$bad_loan)
colnames(df)
head(train)
# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = data,
ratios = c(0.7, 0.15),  #partition data into 70%, 15%, 15% chunks
seed = 1)  #setting a seed will guarantee reproducibility
train <- splits[[1]]
valid <- splits[[2]]
test <- splits[[3]]
head(train)
y <- "bad_loan"
x <- setdiff(names(data), c(y, "int_rate"))  #remove the interest rate column because it's correlated with the outcome
print(x)
gbm_params1 <- list(learn_rate = c(0.01, 0.1),
max_depth = c(3, 5, 9),
sample_rate = c(0.8, 1.0),
col_sample_rate = c(0.2, 0.5, 1.0))
# Train and validate a grid of GBMs
gbm_grid1 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid1",
training_frame = train,
validation_frame = valid,
ntrees = 100,
seed = 1,
hyper_params = gbm_params1)
# Get the grid results, sorted by AUC
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "auc",
decreasing = TRUE)
library(h2o)
h2o.init(nthreads = -1, #Number of threads -1 means use all cores on your machine
max_mem_size = "8G")  #max mem size is the maximum memory to allocate to H2O
# Get the grid results, sorted by AUC
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "auc",
decreasing = TRUE)
knitr::opts_chunk$set(echo = TRUE)
library(h2o)
h2o.init(nthreads = -1, #Number of threads -1 means use all cores on your machine
max_mem_size = "8G")  #max mem size is the maximum memory to allocate to H2O
loan_csv <- "https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv"
data <- h2o.importFile(loan_csv)  # 163,987 rows x 15 columns
dim(data)
colnames(df)
# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = data,
ratios = c(0.7, 0.15),  #partition data into 70%, 15%, 15% chunks
seed = 1)  #setting a seed will guarantee reproducibility
train <- splits[[1]]
valid <- splits[[2]]
test <- splits[[3]]
head(train)
y <- "bad_loan"
x <- setdiff(names(data), c(y, "int_rate"))  #remove the interest rate column because it's correlated with the outcome
print(x)
gbm_params1 <- list(learn_rate = c(0.01, 0.1),
max_depth = c(3, 5, 9),
sample_rate = c(0.8, 1.0),
col_sample_rate = c(0.2, 0.5, 1.0))
# Train and validate a grid of GBMs
gbm_grid1 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid1",
training_frame = train,
validation_frame = valid,
ntrees = 100,
seed = 1,
hyper_params = gbm_params1)
loan_csv <- "https://raw.githubusercontent.com/h2oai/app-consumer-loan/master/data/loan.csv"
data <- h2o.importFile(loan_csv)  # 163,987 rows x 15 columns
dim(data)
df <- as.data.table(data)
colnames(df)
# Partition the data into training, validation and test sets
splits <- h2o.splitFrame(data = data,
ratios = c(0.7, 0.15),  #partition data into 70%, 15%, 15% chunks
seed = 1)  #setting a seed will guarantee reproducibility
train <- splits[[1]]
valid <- splits[[2]]
test <- splits[[3]]
head(train)
y <- "bad_loan"
x <- setdiff(names(data), c(y, "int_rate"))  #remove the interest rate column because it's correlated with the outcome
print(x)
gbm_params1 <- list(learn_rate = c(0.01, 0.1),
max_depth = c(3, 5, 9),
sample_rate = c(0.8, 1.0),
col_sample_rate = c(0.2, 0.5, 1.0))
# Train and validate a grid of GBMs
gbm_grid1 <- h2o.grid("gbm", x = x, y = y,
grid_id = "gbm_grid1",
training_frame = train,
validation_frame = valid,
ntrees = 100,
seed = 1,
hyper_params = gbm_params1)
# Get the grid results, sorted by AUC
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "auc",
decreasing = TRUE)
print(gbm_gridperf1)
# Get the grid results, sorted by AUC
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "residual_deviance",
decreasing = TRUE)
print(gbm_gridperf1)
print(gbm_gridperf1)
gbm_params1
?h2o.getGrid
# Get the grid results, sorted by AUC
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "auc",
decreasing = TRUE)
# Get the grid results, sorted by AUC
gbm_gridperf1 <- h2o.getGrid(grid_id = "gbm_grid1",
sort_by = "residual_deviance",
decreasing = TRUE)
print(gbm_gridperf1)
# Use local data file or download from S3
data_path <- "/home/h2o/data/topics/automl/loan.csv"
if (!file.exists(data_path)) {
data_path <- "https://s3-us-west-2.amazonaws.com/h2o-tutorials/data/topics/automl/loan.csv"
}
# Load data into H2O
train <- h2o.importFile(data_path)
# For classification, the response should be encoded as categorical (aka. "factor" or "enum").
# Let's take a look.
h2o.describe(train)
# Next, let's identify the response & predictor columns by saving them as `x` and `y`.
# The `"int_rate"` column is correlated with the outcome (hence causing label leakage)
# so we want to remove that from the set of our predictors.
y <- "bad_loan"
x <- setdiff(names(train), c(y, "int_rate"))
# Let's convert the response column to a categorical so that H2O will perform classification
train[,y] <- as.factor(train[,y])
# Run AutoML, stopping after 6 models.
# The `max_models` argument specifies the number of individual (or "base") models,
# and does not include the two ensemble models that are trained at the end.
aml <- h2o.automl(y = y, x = x,
training_frame = train,
max_models = 6,
seed = 1)
# The leader model is stored at `aml@leader` and the leaderboard is stored at `aml@leaderboard`.
lb <- aml@leaderboard
# Now we will view a snapshot of the top models.  Here we should see the two Stacked Ensembles
# at or near the top of the leaderboard.  Stacked Ensembles can almost always outperform a single model.
print(lb)
# To view the entire leaderboard, specify the `n` argument of the `print.H2OFrame()`
# function as the total number of rows:
print(lb, n = nrow(lb))
knitr::opts_chunk$set(echo = TRUE)
data_path <- "/home/h2o/data/topics/automl/loan.csv"
if (!file.exists(data_path)) {
data_path <- "https://s3-us-west-2.amazonaws.com/h2o-tutorials/data/topics/automl/loan.csv"
}
## Load H2O library
library(h2o)
## Connect to H2O cluster
h2o.init(nthreads = -1)
## Define data paths
base_path = normalizePath("~/Desktop/H2OTour/intro_r_python_flow/data/")
flights_path = paste0( base_path, "/flights.csv")
weather_path = paste0( base_path, "/weather.csv")
## Ingest data
flights_hex = h2o.importFile(path = flights_path, destination_frame = "flights_hex")
weather_hex = h2o.importFile(path = weather_path, destination_frame = "weather_hex")
